{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JP9Qqn5fq2Y"
      },
      "source": [
        "# Lab 02: Training a Custom Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA2wrFjFna7x"
      },
      "source": [
        "**Objective of this lab**: training a small custom model on the Tiny-ImageNet dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_SzW86f8kM"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecXsQI0_f6pv"
      },
      "outputs": [],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip tiny-imagenet-200.zip -d tiny-imagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vei0UbVTkkPN"
      },
      "source": [
        "We need to adjust the format of the val split of the dataset to be used with ImageFolder.\n",
        "\n",
        "Riformattazione del Validation Set: Questo codice Python riorganizza la cartella __val__. Legge _val_annotations.txt_, che mappa ogni immagine del set di validazione alla sua classe. Quindi crea una sottocartella per ognuna delle 200 classi e sposta le immagini al loro interno, ottenendo la struttura root/{cls}/{fn} necessaria per _ImageFolder_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuUvU_Gug7Gk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "with open('tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt') as f:\n",
        "    for line in f:\n",
        "        fn, cls, *_ = line.split('\\t')\n",
        "        os.makedirs(f'tiny-imagenet/tiny-imagenet-200/val/{cls}', exist_ok=True)\n",
        "\n",
        "        shutil.copyfile(f'tiny-imagenet/tiny-imagenet-200/val/images/{fn}', f'tiny-imagenet/tiny-imagenet-200/val/{cls}/{fn}')\n",
        "\n",
        "shutil.rmtree('tiny-imagenet/tiny-imagenet-200/val/images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt1X5euKfoEd"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),  # Resize to fit the input dimensions of the network\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# root/{classX}/x001.jpg\n",
        "\n",
        "tiny_imagenet_dataset_train = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/train', transform=transform)\n",
        "tiny_imagenet_dataset_val = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/val', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtIrYRaxg6pw"
      },
      "outputs": [],
      "source": [
        "print(f\"Length of train dataset: {len(tiny_imagenet_dataset_train)}\")\n",
        "print(f\"Length of val dataset: {len(tiny_imagenet_dataset_val)}\")\n",
        "\n",
        "# The following code also checks the number of samples per class\n",
        "# from collections import Counter\n",
        "\n",
        "# class_counts = Counter([target for _, target in tiny_imagenet_dataset_val])\n",
        "# for class_label, count in class_counts.items():\n",
        "#     print(f\"Class {class_label}: {count} entries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExF2yRw9mT8G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "train_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_train, batch_size=32, shuffle=True, num_workers=8)\n",
        "val_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_val, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0AIe8afloCR"
      },
      "source": [
        "## Custom model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpdGGfa8lDde"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Define the custom neural network\n",
        "class CustomNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomNet, self).__init__()\n",
        "\n",
        "        # Convolutional sequence (Conv -> ReLU -> MaxPool)\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1: B x 3 x 224 x 224 -> B x 64 x 112 x 112\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 2: B x 64 x 112 x 112 -> B x 128 x 56 x 56\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Calculate the dimensions after the two MaxPools: 224 -> 112 -> 56\n",
        "        # Channels: 128\n",
        "        # Flattened size: 128 * 56 * 56 = 401408 (for batch_size=32)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),   # Flatten the tensor that means B x 128 x 56 x 56 -> B x (128*56*56)\n",
        "            nn.Linear(128 * 56 * 56, 512), # Fully connected layer means B x (128*56*56) -> B x 512\n",
        "            nn.Linear(512, 200) # 200 is the number of classes in TinyImageNet\n",
        "        )\n",
        "\n",
        "    # Forward pass : defines how the data flows through the network\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        logits = self.classifier(x)\n",
        "        return logits   # in logits we have the raw scores for each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM0eatFllREw"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # todo...\n",
        "        # Compute outputs and loss\n",
        "        optimizer.zero_grad() # Reset gradients (as in PDF [cite: 112])\n",
        "        outputs = model(inputs) \n",
        "        loss = criterion(outputs, targets) # Compute loss (as in PDF [cite: 111])\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward() # Backpropagation (compute new gradients) (as in PDF [cite: 113])\n",
        "        optimizer.step() # Update weights (as in PDF [cite: 114])\n",
        "        # .....\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUicYRJamITD"
      },
      "outputs": [],
      "source": [
        "# Validation loop\n",
        "def validate(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "            # todo...\n",
        "            # Calcolo dell'output e della loss\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # ......\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'Validation Loss: {val_loss:.6f} Acc: {val_accuracy:.2f}%')\n",
        "    return val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhr8xxEUmmGD"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lO-VJtZml6t"
      },
      "outputs": [],
      "source": [
        "model = CustomNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "# Run the training process for {num_epochs} epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch, model, train_loader, criterion, optimizer)\n",
        "\n",
        "    # At the end of each training iteration, perform a validation step\n",
        "    val_accuracy = validate(model, val_loader, criterion)\n",
        "\n",
        "    # Best validation accuracy\n",
        "    best_acc = max(best_acc, val_accuracy)\n",
        "\n",
        "\n",
        "print(f'Best validation accuracy: {best_acc:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
