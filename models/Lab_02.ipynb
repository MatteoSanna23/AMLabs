{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JP9Qqn5fq2Y"
      },
      "source": [
        "# Lab 02: Training a Custom Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA2wrFjFna7x"
      },
      "source": [
        "**Objective of this lab**: training a small custom model on the Tiny-ImageNet dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_SzW86f8kM"
      },
      "source": [
        "## Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecXsQI0_f6pv"
      },
      "outputs": [],
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip tiny-imagenet-200.zip -d tiny-imagenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vei0UbVTkkPN"
      },
      "source": [
        "We need to adjust the format of the val split of the dataset to be used with ImageFolder.\n",
        "\n",
        "Riformattazione del Validation Set: Questo codice Python riorganizza la cartella __val__. Legge _val_annotations.txt_, che mappa ogni immagine del set di validazione alla sua classe. Quindi crea una sottocartella per ognuna delle 200 classi e sposta le immagini al loro interno, ottenendo la struttura root/{cls}/{fn} necessaria per _ImageFolder_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuUvU_Gug7Gk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "with open('tiny-imagenet/tiny-imagenet-200/val/val_annotations.txt') as f:\n",
        "    for line in f:\n",
        "        fn, cls, *_ = line.split('\\t')\n",
        "        os.makedirs(f'tiny-imagenet/tiny-imagenet-200/val/{cls}', exist_ok=True)\n",
        "\n",
        "        shutil.copyfile(f'tiny-imagenet/tiny-imagenet-200/val/images/{fn}', f'tiny-imagenet/tiny-imagenet-200/val/{cls}/{fn}')\n",
        "\n",
        "shutil.rmtree('tiny-imagenet/tiny-imagenet-200/val/images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xt1X5euKfoEd"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),  # Resize to fit the input dimensions of the network\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# root/{classX}/x001.jpg\n",
        "\n",
        "tiny_imagenet_dataset_train = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/train', transform=transform)\n",
        "tiny_imagenet_dataset_val = ImageFolder(root='tiny-imagenet/tiny-imagenet-200/val', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtIrYRaxg6pw"
      },
      "outputs": [],
      "source": [
        "print(f\"Length of train dataset: {len(tiny_imagenet_dataset_train)}\")\n",
        "print(f\"Length of val dataset: {len(tiny_imagenet_dataset_val)}\")\n",
        "\n",
        "# The following code also checks the number of samples per class\n",
        "# from collections import Counter\n",
        "\n",
        "# class_counts = Counter([target for _, target in tiny_imagenet_dataset_val])\n",
        "# for class_label, count in class_counts.items():\n",
        "#     print(f\"Class {class_label}: {count} entries\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExF2yRw9mT8G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "train_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_train, batch_size=32, shuffle=True, num_workers=8)\n",
        "val_loader = torch.utils.data.DataLoader(tiny_imagenet_dataset_val, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0AIe8afloCR"
      },
      "source": [
        "## Custom model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpdGGfa8lDde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM0eatFllREw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUicYRJamITD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhr8xxEUmmGD"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lO-VJtZml6t"
      },
      "outputs": [],
      "source": [
        "model = CustomNet().cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "best_acc = 0\n",
        "\n",
        "# Run the training process for {num_epochs} epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(epoch, model, train_loader, criterion, optimizer)\n",
        "\n",
        "    # At the end of each training iteration, perform a validation step\n",
        "    val_accuracy = validate(model, val_loader, criterion)\n",
        "\n",
        "    # Best validation accuracy\n",
        "    best_acc = max(best_acc, val_accuracy)\n",
        "\n",
        "\n",
        "print(f'Best validation accuracy: {best_acc:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
